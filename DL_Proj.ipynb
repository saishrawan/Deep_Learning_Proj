{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "wXRo-dpekaam"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/636_project1_train_images', 'rb') as f:\n",
        "    images = pickle.load(f)\n",
        "\n",
        "with open('/content/636_project1_train_labels', 'rb') as f:\n",
        "    labels = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "IS1okKJPkciL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.numpy()\n",
        "labels = labels.numpy()\n"
      ],
      "metadata": {
        "id": "W0-BijyTker9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.15, random_state=42)\n",
        "#train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n"
      ],
      "metadata": {
        "id": "2LWuHOWckfwK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0 #Preprocessing the data\n",
        "test_images = test_images / 255.0\n",
        "#val_images = val_images / 255.0\n",
        "\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "#val_labels = tf.keras.utils.to_categorical(val_labels, 10)\n"
      ],
      "metadata": {
        "id": "j6_lYeHpkiAS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n"
      ],
      "metadata": {
        "id": "Xh8f3PEOkkOu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stops training when 'val_loss' has stopped decreasing for 20 epochs.\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "\n",
        "# Saves the best model (in terms of validation accuracy) as 'best_model.h5'.\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "# Reduces the learning rate when 'val_loss' has stopped decreasing.\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=20, min_lr=0.00001)\n"
      ],
      "metadata": {
        "id": "juqCfx-7kmk6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # First Convolutional Block\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Convolutional layer\n",
        "    tf.keras.layers.BatchNormalization(),  # Batch normalization\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),  # Convolutional layer with L2 regularization\n",
        "    tf.keras.layers.BatchNormalization(),  # Batch normalization\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),  # Max pooling\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout layer\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),  # Convolutional layer with L2 regularization\n",
        "    tf.keras.layers.BatchNormalization(),  # Batch normalization\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),  # Convolutional layer with L2 regularization\n",
        "    tf.keras.layers.BatchNormalization(),  # Batch normalization\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),  # Max pooling\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout layer\n",
        "\n",
        "    # Fully Connected Block\n",
        "    tf.keras.layers.Flatten(),  # Flatten the 3D output to 1D tensor\n",
        "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001)),  # Fully connected layer with L2 regularization\n",
        "    tf.keras.layers.BatchNormalization(),  # Batch normalization\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout layer\n",
        "\n",
        "    # Output Layer\n",
        "    tf.keras.layers.Dense(10, activation='softmax')  # A softmax layer with 10 output units (one per class)\n",
        "])\n",
        "\n",
        "# Compile the model with Adam optimizer and categorical cross-entropy loss function.\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model for 100 epochs with a batch size of 64.\n",
        "# Use the test set for validation and apply the callbacks.\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=100,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[es, mc, reduce_lr])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yApIT3iFzE3B",
        "outputId": "b447b8e4-e7fe-454a-9590-f9bad1089a10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.8970 - accuracy: 0.1439\n",
            "Epoch 1: val_accuracy improved from -inf to 0.23389, saving model to best_model.h5\n",
            "797/797 [==============================] - 19s 15ms/step - loss: 3.8970 - accuracy: 0.1439 - val_loss: 2.9381 - val_accuracy: 0.2339 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "  6/797 [..............................] - ETA: 9s - loss: 3.4541 - accuracy: 0.2083 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "796/797 [============================>.] - ETA: 0s - loss: 3.2648 - accuracy: 0.2227\n",
            "Epoch 2: val_accuracy improved from 0.23389 to 0.30644, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 3.2647 - accuracy: 0.2228 - val_loss: 2.6656 - val_accuracy: 0.3064 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 3.0082 - accuracy: 0.2538\n",
            "Epoch 3: val_accuracy improved from 0.30644 to 0.33122, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 3.0082 - accuracy: 0.2538 - val_loss: 2.5881 - val_accuracy: 0.3312 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 2.8584 - accuracy: 0.2685\n",
            "Epoch 4: val_accuracy improved from 0.33122 to 0.34778, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 2.8586 - accuracy: 0.2684 - val_loss: 2.5294 - val_accuracy: 0.3478 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 2.7394 - accuracy: 0.2881\n",
            "Epoch 5: val_accuracy improved from 0.34778 to 0.35989, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 2.7394 - accuracy: 0.2880 - val_loss: 2.4813 - val_accuracy: 0.3599 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 2.6250 - accuracy: 0.3119\n",
            "Epoch 6: val_accuracy improved from 0.35989 to 0.38022, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 2.6251 - accuracy: 0.3118 - val_loss: 2.4067 - val_accuracy: 0.3802 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 2.4599 - accuracy: 0.3595\n",
            "Epoch 7: val_accuracy improved from 0.38022 to 0.46011, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 2.4590 - accuracy: 0.3596 - val_loss: 2.1723 - val_accuracy: 0.4601 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 2.2221 - accuracy: 0.4320\n",
            "Epoch 8: val_accuracy improved from 0.46011 to 0.51900, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 2.2220 - accuracy: 0.4321 - val_loss: 1.9628 - val_accuracy: 0.5190 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 2.0717 - accuracy: 0.4780\n",
            "Epoch 9: val_accuracy improved from 0.51900 to 0.55311, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 2.0713 - accuracy: 0.4780 - val_loss: 1.8282 - val_accuracy: 0.5531 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.9492 - accuracy: 0.5107\n",
            "Epoch 10: val_accuracy improved from 0.55311 to 0.57789, saving model to best_model.h5\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 1.9490 - accuracy: 0.5108 - val_loss: 1.7283 - val_accuracy: 0.5779 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 1.8438 - accuracy: 0.5307\n",
            "Epoch 11: val_accuracy improved from 0.57789 to 0.59856, saving model to best_model.h5\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 1.8436 - accuracy: 0.5309 - val_loss: 1.6353 - val_accuracy: 0.5986 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 1.7464 - accuracy: 0.5546\n",
            "Epoch 12: val_accuracy improved from 0.59856 to 0.62111, saving model to best_model.h5\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 1.7463 - accuracy: 0.5546 - val_loss: 1.5324 - val_accuracy: 0.6211 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.6597 - accuracy: 0.5728\n",
            "Epoch 13: val_accuracy did not improve from 0.62111\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 1.6597 - accuracy: 0.5727 - val_loss: 1.5000 - val_accuracy: 0.6140 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 1.5819 - accuracy: 0.5860\n",
            "Epoch 14: val_accuracy improved from 0.62111 to 0.63911, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.5819 - accuracy: 0.5860 - val_loss: 1.4092 - val_accuracy: 0.6391 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 1.5342 - accuracy: 0.5921\n",
            "Epoch 15: val_accuracy improved from 0.63911 to 0.65144, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.5337 - accuracy: 0.5923 - val_loss: 1.3512 - val_accuracy: 0.6514 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.4758 - accuracy: 0.6012\n",
            "Epoch 16: val_accuracy improved from 0.65144 to 0.65544, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.4757 - accuracy: 0.6014 - val_loss: 1.3162 - val_accuracy: 0.6554 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.4328 - accuracy: 0.6107\n",
            "Epoch 17: val_accuracy improved from 0.65544 to 0.66433, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.4329 - accuracy: 0.6107 - val_loss: 1.2677 - val_accuracy: 0.6643 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 1.3955 - accuracy: 0.6195\n",
            "Epoch 18: val_accuracy improved from 0.66433 to 0.66956, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.3951 - accuracy: 0.6193 - val_loss: 1.2390 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 1.3590 - accuracy: 0.6257\n",
            "Epoch 19: val_accuracy did not improve from 0.66956\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.3590 - accuracy: 0.6257 - val_loss: 1.2256 - val_accuracy: 0.6684 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 1.3330 - accuracy: 0.6262\n",
            "Epoch 20: val_accuracy improved from 0.66956 to 0.67489, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.3330 - accuracy: 0.6262 - val_loss: 1.1901 - val_accuracy: 0.6749 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.3035 - accuracy: 0.6315\n",
            "Epoch 21: val_accuracy improved from 0.67489 to 0.67800, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.3036 - accuracy: 0.6316 - val_loss: 1.1714 - val_accuracy: 0.6780 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 1.2804 - accuracy: 0.6345\n",
            "Epoch 22: val_accuracy did not improve from 0.67800\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.2804 - accuracy: 0.6345 - val_loss: 1.1635 - val_accuracy: 0.6738 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.2635 - accuracy: 0.6419\n",
            "Epoch 23: val_accuracy improved from 0.67800 to 0.68233, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.2634 - accuracy: 0.6418 - val_loss: 1.1394 - val_accuracy: 0.6823 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 1.2428 - accuracy: 0.6462\n",
            "Epoch 24: val_accuracy did not improve from 0.68233\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.2432 - accuracy: 0.6461 - val_loss: 1.1335 - val_accuracy: 0.6772 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 1.2269 - accuracy: 0.6473\n",
            "Epoch 25: val_accuracy did not improve from 0.68233\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.2268 - accuracy: 0.6473 - val_loss: 1.1276 - val_accuracy: 0.6813 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.2106 - accuracy: 0.6498\n",
            "Epoch 26: val_accuracy did not improve from 0.68233\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.2106 - accuracy: 0.6498 - val_loss: 1.1210 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 1.1924 - accuracy: 0.6550\n",
            "Epoch 27: val_accuracy improved from 0.68233 to 0.68544, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.1930 - accuracy: 0.6546 - val_loss: 1.1071 - val_accuracy: 0.6854 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 1.1830 - accuracy: 0.6567\n",
            "Epoch 28: val_accuracy did not improve from 0.68544\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.1830 - accuracy: 0.6567 - val_loss: 1.1171 - val_accuracy: 0.6811 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.1740 - accuracy: 0.6586\n",
            "Epoch 29: val_accuracy did not improve from 0.68544\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.1738 - accuracy: 0.6586 - val_loss: 1.0963 - val_accuracy: 0.6850 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.1586 - accuracy: 0.6629\n",
            "Epoch 30: val_accuracy improved from 0.68544 to 0.68689, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.1586 - accuracy: 0.6628 - val_loss: 1.0888 - val_accuracy: 0.6869 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.1423 - accuracy: 0.6654\n",
            "Epoch 31: val_accuracy did not improve from 0.68689\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.1424 - accuracy: 0.6654 - val_loss: 1.0910 - val_accuracy: 0.6852 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.1325 - accuracy: 0.6690\n",
            "Epoch 32: val_accuracy improved from 0.68689 to 0.68700, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.1326 - accuracy: 0.6690 - val_loss: 1.0771 - val_accuracy: 0.6870 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.1274 - accuracy: 0.6706\n",
            "Epoch 33: val_accuracy improved from 0.68700 to 0.68867, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.1277 - accuracy: 0.6706 - val_loss: 1.0798 - val_accuracy: 0.6887 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.1184 - accuracy: 0.6733\n",
            "Epoch 34: val_accuracy improved from 0.68867 to 0.68989, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.1184 - accuracy: 0.6733 - val_loss: 1.0748 - val_accuracy: 0.6899 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.1090 - accuracy: 0.6744\n",
            "Epoch 35: val_accuracy did not improve from 0.68989\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.1092 - accuracy: 0.6742 - val_loss: 1.0851 - val_accuracy: 0.6868 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 1.0985 - accuracy: 0.6794\n",
            "Epoch 36: val_accuracy did not improve from 0.68989\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.0987 - accuracy: 0.6792 - val_loss: 1.0722 - val_accuracy: 0.6869 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.0911 - accuracy: 0.6781\n",
            "Epoch 37: val_accuracy did not improve from 0.68989\n",
            "797/797 [==============================] - 10s 13ms/step - loss: 1.0914 - accuracy: 0.6780 - val_loss: 1.0654 - val_accuracy: 0.6899 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 1.0871 - accuracy: 0.6809\n",
            "Epoch 38: val_accuracy did not improve from 0.68989\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.0874 - accuracy: 0.6807 - val_loss: 1.0870 - val_accuracy: 0.6831 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.0779 - accuracy: 0.6832\n",
            "Epoch 39: val_accuracy did not improve from 0.68989\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.0776 - accuracy: 0.6833 - val_loss: 1.0666 - val_accuracy: 0.6898 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 1.0748 - accuracy: 0.6840\n",
            "Epoch 40: val_accuracy improved from 0.68989 to 0.69289, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.0750 - accuracy: 0.6839 - val_loss: 1.0642 - val_accuracy: 0.6929 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 1.0619 - accuracy: 0.6867\n",
            "Epoch 41: val_accuracy did not improve from 0.69289\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.0622 - accuracy: 0.6866 - val_loss: 1.0688 - val_accuracy: 0.6919 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 1.0619 - accuracy: 0.6878\n",
            "Epoch 42: val_accuracy did not improve from 0.69289\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 1.0619 - accuracy: 0.6878 - val_loss: 1.0676 - val_accuracy: 0.6921 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.0466 - accuracy: 0.6926\n",
            "Epoch 43: val_accuracy did not improve from 0.69289\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.0464 - accuracy: 0.6926 - val_loss: 1.0856 - val_accuracy: 0.6847 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.0485 - accuracy: 0.6923\n",
            "Epoch 44: val_accuracy did not improve from 0.69289\n",
            "797/797 [==============================] - 10s 13ms/step - loss: 1.0481 - accuracy: 0.6924 - val_loss: 1.0717 - val_accuracy: 0.6903 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 1.0417 - accuracy: 0.6936\n",
            "Epoch 45: val_accuracy did not improve from 0.69289\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.0423 - accuracy: 0.6935 - val_loss: 1.0714 - val_accuracy: 0.6892 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 1.0355 - accuracy: 0.6971\n",
            "Epoch 46: val_accuracy improved from 0.69289 to 0.69333, saving model to best_model.h5\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.0358 - accuracy: 0.6972 - val_loss: 1.0724 - val_accuracy: 0.6933 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 1.0282 - accuracy: 0.7000\n",
            "Epoch 47: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.0282 - accuracy: 0.7000 - val_loss: 1.0733 - val_accuracy: 0.6848 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 1.0279 - accuracy: 0.6983\n",
            "Epoch 48: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.0278 - accuracy: 0.6984 - val_loss: 1.0700 - val_accuracy: 0.6860 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.0142 - accuracy: 0.7036\n",
            "Epoch 49: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 1.0140 - accuracy: 0.7038 - val_loss: 1.0710 - val_accuracy: 0.6896 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.0129 - accuracy: 0.7048\n",
            "Epoch 50: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.0130 - accuracy: 0.7048 - val_loss: 1.0773 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.0053 - accuracy: 0.7066\n",
            "Epoch 51: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.0056 - accuracy: 0.7065 - val_loss: 1.0857 - val_accuracy: 0.6878 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 1.0044 - accuracy: 0.7073\n",
            "Epoch 52: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 1.0044 - accuracy: 0.7074 - val_loss: 1.0799 - val_accuracy: 0.6856 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 0.9974 - accuracy: 0.7097\n",
            "Epoch 53: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 0.9974 - accuracy: 0.7097 - val_loss: 1.0825 - val_accuracy: 0.6876 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 0.9935 - accuracy: 0.7125\n",
            "Epoch 54: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 0.9940 - accuracy: 0.7124 - val_loss: 1.0873 - val_accuracy: 0.6871 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 0.9948 - accuracy: 0.7088\n",
            "Epoch 55: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 0.9947 - accuracy: 0.7089 - val_loss: 1.0830 - val_accuracy: 0.6928 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 0.9871 - accuracy: 0.7132\n",
            "Epoch 56: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 0.9871 - accuracy: 0.7132 - val_loss: 1.0820 - val_accuracy: 0.6846 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 0.9856 - accuracy: 0.7154\n",
            "Epoch 57: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 0.9856 - accuracy: 0.7154 - val_loss: 1.0858 - val_accuracy: 0.6850 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 0.9831 - accuracy: 0.7141\n",
            "Epoch 58: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 0.9833 - accuracy: 0.7142 - val_loss: 1.0821 - val_accuracy: 0.6868 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 0.9744 - accuracy: 0.7199\n",
            "Epoch 59: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 0.9741 - accuracy: 0.7199 - val_loss: 1.0824 - val_accuracy: 0.6869 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 0.9791 - accuracy: 0.7177\n",
            "Epoch 60: val_accuracy did not improve from 0.69333\n",
            "797/797 [==============================] - 11s 13ms/step - loss: 0.9798 - accuracy: 0.7175 - val_loss: 1.0907 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 60: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the best model\n",
        "saved_model = load_model('best_model.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "#test_loss, test_acc = saved_model.evaluate(test_images, test_labels)\n",
        "#print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "id": "xickKuWvlAOC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "## My model weights are saved in 'best_model.h5'. Use this weights to test.\n",
        "from tensorflow.keras import models\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "model = models.load_model(\"best_model.h5\")\n",
        "test_labels = pickle.load(open(\"./636_project1_test_labels\", 'rb'))\n",
        "test_images = pickle.load(open(\"./636_project1_test_images\", 'rb'))\n",
        "\n",
        "\n",
        "# Include your data preprocessing code if applicable\n",
        "# <your data preprocessing code>\n",
        "# Include your data preprocessing code if applicable\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "your_score = round(test_acc*1000) / 10\n",
        "print(f\"Your Score: {your_score}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ebibPy95ZjZf",
        "outputId": "f13691df-6c3e-4cd3-96bc-6d047216457d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom tensorflow.keras import models\\nimport pickle\\nimport tensorflow as tf\\n\\nmodel = models.load_model(\"best_model.h5\")\\ntest_labels = pickle.load(open(\"./636_project1_test_labels\", \\'rb\\'))\\ntest_images = pickle.load(open(\"./636_project1_test_images\", \\'rb\\'))\\n\\n\\n# Include your data preprocessing code if applicable\\n# <your data preprocessing code>\\n# Include your data preprocessing code if applicable\\n\\n\\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\\nyour_score = round(test_acc*1000) / 10\\nprint(f\"Your Score: {your_score}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ALOSEcDWblzV"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}